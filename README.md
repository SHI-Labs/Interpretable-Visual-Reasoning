# Interpretable Visual Reasoning via Induced Symbolic Space

This is the implementation of [Interpretable Visual Reasoning via Induced Symbolic Space](https://arxiv.org/abs/2011.11603). 

**Note:**
Our code for OCCAM (Object-Centric Compositional Attention Model) will be released soon, stay tuned.


## Introduction
Our proposed OCCAM framework performs pure object-level reasoning and achieves a new state-of-the-art without human-annotated functional programs on the CLEVR dataset. Our framework makes the object-word cooccurrence information avaiable, which enables induction of the concepts and super concepts based on the inclusiveness and the mutual exclusiveness of words’ visual mappings. When working on concepts instead of visual features, OCCAM achieves comparable performance, proving the accuracy and sufﬁciency of the induced concepts.

![OCCAM](.github/teaser.png)

