# OCCAM: Object-Centric Compositional Attention Model

This is the implementation of [Interpretable Visual Reasoning via Induced Symbolic Space](). The code will be released soon.

## Introduction
Our proposed OCCAM framework performs pure object-level reasoning and achieves a new state-of-the-art without human-annotated functional programs on the CLEVR dataset. Our framework makes the object-word cooccurrence information avaiable, which enables induction of the concepts and super concepts based on the inclusiveness and the mutual exclusiveness of words’ visual mappings. When working on concepts instead of visual features, OCCAM achieves comparable performance, proving the accuracy and sufﬁciency of the induced concepts.

![OCCAM](.github/teaser.png)

